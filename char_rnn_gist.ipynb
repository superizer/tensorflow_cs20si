{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clean, no_frills character-level generative language model.\n",
    "Created by Danijar Hafner (danijar.com), edited by Chip Huyen\n",
    "for the class CS 20SI: \"TensorFlow for Deep Learning Research\"\n",
    "Based on Andrej Karpathy's blog: \n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/arvix_abstracts.txt'\n",
    "HIDDEN_SIZE = 200\n",
    "BATCH_SIZE = 64\n",
    "NUM_STEPS = 50\n",
    "SKIP_STEP = 40\n",
    "TEMPRATURE = 0.7\n",
    "LR = 0.003\n",
    "LEN_GENERATED = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_encode(text, vocab):\n",
    "    return [vocab.index(x) + 1 for x in text if x in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_decode(array, vocab):\n",
    "    return ''.join([vocab[x - 1] for x in array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename, vocab, window=NUM_STEPS, overlap=NUM_STEPS//2):\n",
    "    for text in open(filename):\n",
    "        text = vocab_encode(text, vocab)\n",
    "        for start in range(0, len(text) - window, overlap):\n",
    "            chunk = text[start: start + window]\n",
    "            chunk += [0] * (window - len(chunk))\n",
    "            yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_batch(stream, batch_size=BATCH_SIZE):\n",
    "    batch = []\n",
    "    for element in stream:\n",
    "        batch.append(element)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rnn(seq, hidden_size=HIDDEN_SIZE):\n",
    "    cell = tf.contrib.rnn.GRUCell(hidden_size)\n",
    "    in_state = tf.placeholder_with_default(\n",
    "            cell.zero_state(tf.shape(seq)[0], tf.float32), [None, hidden_size])\n",
    "    # this line to calculate the real length of seq\n",
    "    # all seq are padded to be of the same length which is NUM_STEPS\n",
    "    length = tf.reduce_sum(tf.reduce_max(tf.sign(seq), 2), 1)\n",
    "    output, out_state = tf.nn.dynamic_rnn(cell, seq, length, in_state)\n",
    "    return output, in_state, out_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
